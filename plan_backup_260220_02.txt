 Ready to code?

 Here is Claude's plan:
╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌
 arXiv RAG v2 - 아키텍처 재설계 계획

 프로젝트 목적: RAG 구조 실험용 research platform
 중점 가치: 실험 재현성, 구조 확장성
 작성일: 2026-02-20 (Updated)

 ---
 0. v1 → v2 마이그레이션 전략

 코드 재사용 분석 결과
 ┌────────────┬─────────┬───────┬────────────────────────────────────────────┐
 │  카테고리  │ 파일 수 │  LOC  │                  재사용성                  │
 ├────────────┼─────────┼───────┼────────────────────────────────────────────┤
 │ KEEP AS-IS │ 20      │ 6,523 │ 100% (parsing, embedding, collection core) │
 ├────────────┼─────────┼───────┼────────────────────────────────────────────┤
 │ MODIFY     │ 11      │ 4,117 │ ~75% (retriever, API - storage layer swap) │
 ├────────────┼─────────┼───────┼────────────────────────────────────────────┤
 │ REWRITE    │ 8       │ 2,285 │ 0% (scripts - 새 파이프라인)               │
 ├────────────┼─────────┼───────┼────────────────────────────────────────────┤
 │ DELETE     │ 15      │ 5,119 │ N/A (Supabase 전용 코드)                   │
 └────────────┴─────────┴───────┴────────────────────────────────────────────┘
 총 재사용률: ~51% → 새 repo 생성 + cherry-pick 권장

 v2 repo 생성 절차

 # Step 1: v1 최종 상태 이미 push 완료 (2026-02-20 오전)
 # git tag v1-final → 불필요 (현재 상태 그대로 유지)

 # Step 2: GitHub에서 v2 repo 생성
 # Repository name: arxiv-rag-v2

 # Step 3: 로컬에서 remote 변경
 git remote remove origin
 git remote add origin git@github.com:USERNAME/arxiv-rag-v2.git

 # Step 4: 불필요한 파일 삭제 후 push
 # (아래 DELETE 목록 참조)

 재사용 가능한 핵심 모듈

 src/collection/     # 100% 재사용 (arxiv_client, semantic_scholar, downloader)
 src/parsing/        # 100% 재사용 (latex_parser, marker_parser, models)
 src/embedding/      # 100% 재사용 (chunker, bge_embedder, openai_embedder, models)
 src/rag/reranker.py # 95% 재사용 (BGEReranker)
 src/utils/          # 100% 재사용 (config, logging, gemini)

 삭제 대상 (v2에서 제거)

 src/storage/supabase_client.py     # Qdrant로 대체
 scripts/07_openai_embed_sample.py  # v1 전용
 scripts/08_colbert_embed.py        # v1 전용
 scripts/09_embed_direct.py         # v1 전용
 scripts/embed_recovered_papers.py  # v1 workaround
 scripts/reparse_zero_sections.py   # v1 workaround
 supabase/migrations/*              # Supabase 전용

 ---
 확정된 설계 결정

 저장소 분리 전략

 ┌─────────────────────────────────────────────────────────────────┐
 │                        Query Flow                               │
 ├─────────────────────────────────────────────────────────────────┤
 │  User Query                                                     │
 │      ↓                                                          │
 │  BGE-M3 Embedding (dense + sparse)                             │
 │      ↓                                                          │
 │  Qdrant Search → top_k chunk_ids + scores                      │
 │      ↓                                                          │
 │  Supabase: SELECT * FROM chunks WHERE chunk_id IN (...)        │
 │      ↓                                                          │
 │  Reranker (optional)                                           │
 │      ↓                                                          │
 │  LLM Response                                                   │
 └─────────────────────────────────────────────────────────────────┘
 ┌──────────┬─────────────────────┬─────────────────────────────────────────────────┐
 │  저장소  │        역할         │                  테이블/컬렉션                  │
 ├──────────┼─────────────────────┼─────────────────────────────────────────────────┤
 │ Supabase │ Raw data + Metadata │ papers, chunks (no vectors), equations, figures │
 ├──────────┼─────────────────────┼─────────────────────────────────────────────────┤
 │ Qdrant   │ Vector search       │ arxiv_chunks (dense, sparse, colbert, openai)   │
 └──────────┴─────────────────────┴─────────────────────────────────────────────────┘
 ---
 Phase 1: Supabase 테이블 재설계

 1.1 테이블 변경 요약
 ┌───────────┬────────────────────────────────────────────────────┐
 │  테이블   │                     변경 사항                      │
 ├───────────┼────────────────────────────────────────────────────┤
 │ papers    │ 변경 없음                                          │
 ├───────────┼────────────────────────────────────────────────────┤
 │ chunks    │ 4개 vector 컬럼 DROP, metadata 유지                │
 ├───────────┼────────────────────────────────────────────────────┤
 │ equations │ embedding 컬럼 DROP (Qdrant로 이전)                │
 ├───────────┼────────────────────────────────────────────────────┤
 │ figures   │ embedding 컬럼 DROP (향후 VLM 추가 시 Qdrant 사용) │
 └───────────┴────────────────────────────────────────────────────┘
 1.2 chunks 테이블 (After)

 -- Vector 컬럼 제거 후 lightweight metadata 테이블
 CREATE TABLE chunks (
     id SERIAL PRIMARY KEY,
     chunk_id TEXT UNIQUE NOT NULL,
     paper_id TEXT NOT NULL REFERENCES papers(arxiv_id) ON DELETE CASCADE,
     content TEXT NOT NULL,
     section_title TEXT,
     chunk_type TEXT DEFAULT 'text',  -- text, abstract, equation
     chunk_index INTEGER,
     token_count INTEGER,
     metadata JSONB,
     created_at TIMESTAMP DEFAULT NOW()
 );

 -- 조회용 인덱스
 CREATE INDEX idx_chunks_paper_id ON chunks(paper_id);
 CREATE INDEX idx_chunks_chunk_id ON chunks(chunk_id);

 1.3 데이터 초기화 전략

 Migration SQL 불필요 - 데이터 전체 재수집 예정이므로 기존 테이블 TRUNCATE 후 새 스키마로 재생성.

 -- v2 초기화 시 실행 (Migration 대신)
 TRUNCATE TABLE chunks CASCADE;
 TRUNCATE TABLE equations CASCADE;
 TRUNCATE TABLE figures CASCADE;
 TRUNCATE TABLE papers CASCADE;

 -- 이후 새 스키마로 테이블 재생성 (vector 컬럼 없음)

 ---
 Phase 2: Qdrant 컬렉션 설계

 2.1 컬렉션 스키마

 # src/storage/qdrant_client.py

 COLLECTION_CONFIG = {
     "collection_name": "arxiv_chunks",
     "vectors_config": {
         "dense_bge": VectorParams(size=1024, distance=Distance.COSINE),
         "dense_openai": VectorParams(size=1024, distance=Distance.COSINE),
     },
     "sparse_vectors_config": {
         "sparse_bge": SparseVectorParams(),  # Native inverted index
     },
     # ColBERT: 별도 multivector 필드 또는 payload 저장
 }

 # Payload schema
 PAYLOAD_SCHEMA = {
     "chunk_id": str,       # Supabase lookup key
     "paper_id": str,       # For filtering
     "section_title": str,  # For context
     "chunk_type": str,     # text, abstract, equation
     "content": str,        # Optional: 중복 저장 시
 }

 2.2 Equation Chunks

 수식 text_description → chunk로 변환하여 Qdrant 저장 (✓ 코드 완료)
 - ChunkType.EQUATION
 - include_equations=True 설정 시 활성화

 ---
 Phase 3: 코드 변경 목록

 3.1 Storage Layer
 ┌────────────────────────────────┬────────────────────────────────────────────────────────────┐
 │              파일              │                         변경 내용                          │
 ├────────────────────────────────┼────────────────────────────────────────────────────────────┤
 │ src/storage/supabase_client.py │ vector INSERT/UPDATE 로직 제거, content lookup 메서드 추가 │
 ├────────────────────────────────┼────────────────────────────────────────────────────────────┤
 │ src/storage/qdrant_client.py   │ ✓ 이미 구현됨, upsert/search 메서드                        │
 ├────────────────────────────────┼────────────────────────────────────────────────────────────┤
 │ src/storage/__init__.py        │ ✓ export 완료                                              │
 └────────────────────────────────┴────────────────────────────────────────────────────────────┘
 3.2 Embedding Layer
 ┌──────────────────────────┬─────────────────────────────────────────────────┐
 │           파일           │                    변경 내용                    │
 ├──────────────────────────┼─────────────────────────────────────────────────┤
 │ src/embedding/models.py  │ EmbeddedChunk.to_db_dict() → Qdrant용 변환 추가 │
 ├──────────────────────────┼─────────────────────────────────────────────────┤
 │ src/embedding/chunker.py │ ✓ equation chunking 완료                        │
 └──────────────────────────┴─────────────────────────────────────────────────┘
 3.3 Retrieval Layer
 ┌─────────────────────────────┬───────────────────────────────────────────────┐
 │            파일             │                   변경 내용                   │
 ├─────────────────────────────┼───────────────────────────────────────────────┤
 │ src/rag/retriever.py        │ Supabase RPC 호출 → Qdrant client 호출로 변경 │
 ├─────────────────────────────┼───────────────────────────────────────────────┤
 │ src/rag/qdrant_retriever.py │ ✓ 이미 구현됨                                 │
 ├─────────────────────────────┼───────────────────────────────────────────────┤
 │ src/rag/__init__.py         │ ✓ export 완료                                 │
 └─────────────────────────────┴───────────────────────────────────────────────┘
 3.4 Scripts
 ┌───────────────────────────────────┬────────────────────────────────┐
 │               파일                │           변경 내용            │
 ├───────────────────────────────────┼────────────────────────────────┤
 │ scripts/04_embed.py               │ Qdrant upsert로 변경           │
 ├───────────────────────────────────┼────────────────────────────────┤
 │ scripts/07_openai_embed_sample.py │ Qdrant upsert로 변경           │
 ├───────────────────────────────────┼────────────────────────────────┤
 │ scripts/08_colbert_embed.py       │ Qdrant upsert로 변경           │
 ├───────────────────────────────────┼────────────────────────────────┤
 │ scripts/migrate_to_qdrant.py      │ 신규: 기존 데이터 마이그레이션 │
 └───────────────────────────────────┴────────────────────────────────┘
 ---
 Phase 4: 구현 순서

 Step 1: Supabase Migration 실행
   └── 20260220000001_remove_vectors.sql 적용
   └── 기존 데이터 TRUNCATE (새로 수집 예정)

 Step 2: Qdrant Collection 생성
   └── create_collection() 실행
   └── 인덱스 설정 확인

 Step 3: supabase_client.py 수정
   └── vector 관련 메서드 제거
   └── get_chunks_by_ids() 메서드 추가

 Step 4: retriever.py 수정
   └── Supabase RPC → Qdrant 호출
   └── chunk_id로 Supabase content 조회

 Step 5: Embedding scripts 수정
   └── Supabase INSERT (metadata only)
   └── Qdrant upsert (vectors)

 Step 6: 검증
   └── End-to-end search 테스트

 ---
 Phase 5: 데이터 재수집 파이프라인

 5.1 수집 전략 요약

 - 기간: 2024년 1월 ~ 현재 (14개월)
 - 목표: Top 1000 논문 선별
 - 방식: NG 키워드 반복 학습 + LLM 분류 + Stratified Sampling

 5.2 파이프라인 단계

 월간 논문 (~15k)
   → Category + Keyword 필터 (~2k)
   → NG Keyword 자동 필터 (edge cases ~500)
   → Gemini 분류 + 새 NG 키워드 추출
   → 사람 검수 → 다음 달

 14개월 완료 후
   → Semantic Filtering (~4-5k)
   → 4가지 스코어링 (Citation, Recency, Semantic, Stratified)
   → Top 1000 선별

 ---
 검증 계획

 Supabase Migration 검증

 -- Vector 컬럼 제거 확인
 SELECT column_name FROM information_schema.columns
 WHERE table_name = 'chunks' AND column_name LIKE 'embedding%';
 -- Expected: 0 rows

 -- Function 제거 확인
 SELECT routine_name FROM information_schema.routines
 WHERE routine_name LIKE 'match_chunks%';
 -- Expected: 0 rows

 Qdrant 연동 검증

 # End-to-end search test
 from src.rag.qdrant_retriever import QdrantHybridRetriever

 retriever = QdrantHybridRetriever()
 response = retriever.search("attention mechanism", top_k=5)
 assert len(response.results) > 0
 assert response.search_time_ms < 500  # Target latency

 전체 파이프라인 검증

 # 1. Qdrant health
 curl http://localhost:6333/health

 # 2. Search API test
 python -c "from src.rag import qdrant_hybrid_search; print(qdrant_hybrid_search('transformer', top_k=3))"

 # 3. Content lookup test
 python -c "from src.storage import get_supabase_client; c = get_supabase_client(); print(c.get_chunks_by_ids(['chunk_id_1']))"

 ---
 Appendix A: 데이터 재수집 상세 (14개월)

 2.1 현재 문제

 - 1개월 데이터만 보유 (2025년 1월)
 - 인용수 기반 선별 → 최신 논문 불리 (12:1 불이익)
 - 다양성 제어 없음 (토픽, 카테고리, 기관)

 2.2 수집 전략: 반복적 NG 키워드 학습 파이프라인

 ┌─────────────────────────────────────────────────────────┐
 │  0단계: 초기 NG 키워드 설정 (Pre-requisite)              │
 │    → NGwords_gpt.txt 기반 11개 카테고리, ~193개 키워드   │
 │    → data/ng_keywords.json 생성                         │
 ├─────────────────────────────────────────────────────────┤
 │                    월별 반복 (14회)                      │
 ├─────────────────────────────────────────────────────────┤
 │  월간 논문 (≈15k)                                       │
 │    → 1단계: Category + Positive Keyword → ~2k           │
 │    → 2단계: NG Keyword 자동 필터링 → edge cases ~500     │
 │    → 3단계: Gemini 분류 + NG 키워드 추출                 │
 │    → 4단계: 사람 검수 → NG 키워드 업데이트               │
 │    → 다음 달로 이동                                      │
 ├─────────────────────────────────────────────────────────┤
 │  14개월 완료 후                                          │
 │    → 5단계: Semantic Filtering → ~4-5k                  │
 │    → 6단계: 다중 스코어링 → 랭킹                         │
 │    → 7단계: Stratified Sampling → Top 1000              │
 └─────────────────────────────────────────────────────────┘

 핵심 전략: Precision ↓, Recall ↑ 로 시작 → 점진적으로 NG 키워드 정교화

 NG 키워드 소스: NGwords_gpt.txt (GPT 제안, 11개 카테고리)

 2.3 1단계: 기본 필터링 (Category + Positive Keyword)

 # arXiv categories
 CATEGORIES = ["cs.AI", "cs.LG", "cs.CL", "cs.CV", "stat.ML", "cs.IR", "cs.NE"]

 # Keywords (기존 arxiv_client.py 활용)
 KEYWORDS = PRIMARY_KEYWORDS + MODEL_FAMILIES + TECHNIQUE_KEYWORDS
 예상: 월간 15k → 2k

 2.4 0단계: 초기 NG 키워드 설정 (Pre-requisite)

 소스 파일: /home/ajh428/projects/arxiv-rag-v1/NGwords_gpt.txt

 GPT 제안 기반 11개 카테고리, ~193개 키워드로 초기화:

 # data/ng_keywords.json - 초기 설정
 {
     "version": "2026-02-20",
     "categories": {
         "biomedical": [
             "bio", "biomedical", "biomedicine", "clinical", "medical", "medicine",
             "healthcare", "hospital", "patient", "diagnosis", "therapy", "treatment",
             "disease", "pathology", "radiology", "ultrasound", "x-ray", "ct scan",
             "mri", "medical imaging", "histopathology", "microscopy", "genomics",
             "genome", "proteomics", "protein", "rna", "dna", "gene expression",
             "drug", "drug discovery", "drug design", "pharmacology", "chemistry",
             "molecule", "molecular", "biochemistry", "protein folding", "protein docking"
         ],
         "chemistry_materials": [
             "material science", "materials science", "metallurgy", "crystal",
             "crystallography", "polymer", "nanomaterial", "nanoparticle",
             "composite material", "battery", "lithium ion", "solid state",
             "semiconductor", "photonic", "quantum chemistry", "quantum physics",
             "particle physics", "condensed matter", "thermodynamics", "fluid mechanics",
             "computational fluid dynamics", "cfd", "finite element", "finite element method",
             "fem", "simulation", "numerical simulation", "physics-based modeling",
             "mechanical engineering", "structural analysis"
         ],
         "earth_science": [
             "climate", "climate change", "meteorology", "weather", "forecasting",
             "atmospheric", "geoscience", "geology", "seismology", "earthquake",
             "hydrology", "oceanography", "remote sensing", "satellite imagery",
             "hyperspectral", "lidar", "geospatial", "gis", "topography", "terrain",
             "agriculture", "crop", "soil", "environmental monitoring", "ecology"
         ],
         "robotics_control": [
             "robotics", "robot control", "motion planning", "path planning", "slam",
             "localization", "mapping", "control system", "pid controller", "kalman filter",
             "signal processing", "time series forecasting", "sensor fusion", "radar",
             "sonar", "audio signal processing", "speech enhancement", "speech separation",
             "beamforming"
         ],
         "finance_social": [
             "finance", "financial", "stock market", "trading", "portfolio",
             "risk management", "cryptocurrency", "blockchain", "economics", "economic",
             "macroeconomic", "microeconomic", "game theory", "social network analysis",
             "sociology", "demography", "survey analysis", "behavioral analysis",
             "opinion mining"
         ],
         "domain_cv": [
             "face recognition", "facial expression", "biometric", "fingerprint",
             "iris recognition", "surveillance", "crowd counting", "traffic monitoring",
             "license plate", "object tracking", "pedestrian detection",
             "industrial inspection", "defect detection", "quality inspection"
         ],
         "education_psychology": [
             "education", "educational", "learning analytics", "student performance",
             "intelligent tutoring", "psychology", "cognitive science", "cognitive modeling",
             "behavior modeling", "emotion recognition", "affective computing"
         ],
         "hardware_systems": [
             "fpga", "asic", "vlsi", "circuit design", "hardware acceleration",
             "embedded system", "microcontroller", "operating system kernel",
             "network protocol", "routing algorithm", "wireless communication",
             "5g", "6g", "antenna design"
         ]
     },
     "flat_keywords": [],  # 카테고리 합산 (자동 생성)
     "changelog": []
 }

 초기화 스크립트:
 # NGwords_gpt.txt → data/ng_keywords.json 변환
 python scripts/init_ng_keywords.py

 ---
 2.5 2단계: NG Keyword 자동 필터링

 # 초기 NG 키워드 로드 (193개)
 def load_ng_keywords() -> list:
     with open("data/ng_keywords.json") as f:
         data = json.load(f)
     return data["flat_keywords"]

 NG_KEYWORDS = load_ng_keywords()

 def filter_by_ng_keywords(papers: list, ng_keywords: list) -> tuple:
     """
     Returns:
         (filtered_out, edge_cases)
     """
     filtered_out = []
     edge_cases = []

     for paper in papers:
         text = f"{paper.title} {paper.abstract}".lower()

         # NG 키워드 매칭
         matched_ng = [kw for kw in ng_keywords if kw.lower() in text]

         if matched_ng:
             filtered_out.append(paper)
         else:
             edge_cases.append(paper)

     return filtered_out, edge_cases
 예상: 2k → edge cases ~500

 2.6 3단계: Gemini 분류 + NG 키워드 추출

 # gemini-3-flash-preview 사용 (2025년 12월 최신)
 PROMPT = """
 논문 제목: {title}
 초록: {abstract}

 이 논문이 LLM / DL / ML RAG 실험용 데이터셋에 적합한지 판단하세요.

 판단 기준:
 - LLM, foundation model, pretraining, alignment, reasoning, multimodal, RAG, retrieval, architecture 연구는 적합
 - 특정 도메인 응용 (의료, 생물, 화학, 로봇, 기후, 산업, 신호처리, 물리 시뮬레이션 등)은 부적합

 출력:
 1. 적합 여부: YES / NO
 2. NO인 경우, **도메인 기반 단일 키워드** 3개를 추출하세요.
    - 반드시 **짧고 일반적인 도메인 명사**
    - 복합어, 문장형 금지
    - 예: "Medical", "Biology", "Chemistry", "Robotics", "Climate", "Signal", "Finance"

 응답 형식 (엄격히 준수):
 SUITABLE: YES/NO
 NG_KEYWORDS: keyword1, keyword2, keyword3   (NO인 경우만)
 """

 def classify_and_extract_ng(papers: list) -> tuple:
     """
     Returns:
         (suitable_papers, new_ng_keywords)
     """
     suitable = []
     new_ng_keywords = set()

     for paper in papers:
         response = gemini.generate(PROMPT.format(
             title=paper.title,
             abstract=paper.abstract
         ))

         if "SUITABLE: YES" in response:
             suitable.append(paper)
         else:
             # NG 키워드 추출
             keywords = parse_ng_keywords(response)
             new_ng_keywords.update(keywords)

     return suitable, new_ng_keywords
 예상: edge cases 500 → suitable ~300, 새 NG 키워드 ~50

 2.7 4단계: 사람 검수 (Human-in-the-loop)

 # 월별 검수 체크리스트
 1. 새로 추출된 NG 키워드 검토
 2. 오탐 키워드 제거 (LLM 관련 키워드가 포함된 경우)
 3. 누락된 키워드 수동 추가
 4. NG 키워드 파일 업데이트
 5. 다음 달 수집 진행

 # data/ng_keywords.json (버전 관리)
 {
     "version": "2026-02-01",
     "keywords": [...],
     "changelog": [
         {"date": "2026-02-01", "added": [...], "removed": [...]}
     ]
 }

 2.8 5단계: Semantic Filtering (14개월 완료 후)

 ANCHOR_QUERY = """
 state of the art research in large language models,
 deep learning architectures, training optimization,
 multimodal models, alignment, reasoning
 """

 # BGE-M3 임베딩 후 cosine similarity ≥ 0.55
 예상: ~4-5k 논문 확보

 2.9 6단계: 다중 스코어링 (4가지 지표)

 FinalScore = (
     0.40 * CitationScore +      # Semantic Scholar citation / months
     0.30 * RecencyBoost +       # exp(-age / τ)
     0.20 * SemanticImpact +     # cosine similarity with anchor
     0.10 * StratifiedBonus      # 분야 균형 가산점
 )

 # τ = 6 (6개월 반감기)

 제외된 지표:
 - VenueWeight: arXiv preprint에서 venue 정보 제한적
 - CommunitySignal: GitHub/Twitter API 복잡도 높음

 2.10 7단계: Stratified Sampling

 TOPIC_DISTRIBUTION = {
     "LLM Pretraining": 200,        # 20%
     "Reasoning/RL/Alignment": 200,  # 20%
     "Multimodal": 150,              # 15%
     "Retrieval/RAG": 150,           # 15%
     "Architecture": 100,            # 10%
     "Optimization/Efficiency": 100, # 10%
     "Evaluation/Benchmark": 100,    # 10%
 }

 분류 방법: LLM 분류 + embedding clustering + keyword heuristic 혼합

 2.11 검증 메트릭

 ✓ Temporal correlation < 0.2 (시간 편향 제거)
 ✓ Topic entropy > 3.5 bits (다양성)
 ✓ Institution Gini < 0.6 (기관 균형)
 ✓ Category coverage: 모든 카테고리 ≥ 5%

 2.12 구현 파일

 신규: data/ng_keywords.json            # NG 키워드 저장소 (버전 관리)
 신규: scripts/init_ng_keywords.py      # NGwords_gpt.txt → JSON 변환
 신규: scripts/collect_extended.py      # 14개월 수집
 신규: scripts/filter_ng_keywords.py    # NG 키워드 자동 필터링
 신규: scripts/classify_papers.py       # LLM 분류 + NG 키워드 추출 (gemini-3-flash-preview)
 신규: scripts/semantic_filter.py       # BGE-M3 anchor similarity
 신규: scripts/compute_scores.py        # 다중 스코어링
 신규: scripts/stratified_sample.py     # 분야별 샘플링
 신규: src/collection/ng_keywords.py    # NG 키워드 관리 모듈
 신규: src/collection/selection.py      # Top-1000 알고리즘
 수정: src/collection/arxiv_client.py   # 날짜 범위 확장

 ---
 Appendix B: 성능 목표
 ┌─────────────────┬─────────┬─────────┐
 │      지표       │  현재   │  목표   │
 ├─────────────────┼─────────┼─────────┤
 │ MRR             │ 0.614   │ ≥ 0.75  │
 ├─────────────────┼─────────┼─────────┤
 │ Hybrid Latency  │ 3,578ms │ < 700ms │
 ├─────────────────┼─────────┼─────────┤
 │ Sparse Latency  │ 2,599ms │ < 500ms │
 ├─────────────────┼─────────┼─────────┤
 │ 데이터 커버리지 │ 1개월   │ 14개월  │
 └─────────────────┴─────────┴─────────┘
 ---
 Appendix C: DeepSeek-R1 검색 이슈 진단 (2026-02-20)

 진단 결과

 결론: 현재 시스템에서 DeepSeek-R1 검색은 정상 동작 중

 Query: "DeepSeek-R1 모델에 대해 설명해 주세요"
 Latency: 15,323ms

 Top 5 Results:
   1. [2501.12948v2] Introduction (score: 0.0164) ✅ DeepSeek-R1
   2. [2501.12948v2] Experiment (score: 0.0161)   ✅ DeepSeek-R1
   3. [2501.19393v3] s1.1 (score: 0.0159)
   4. [2501.17030v1] Reinforcement Learning (score: 0.0156)
   5. [2501.12948v2] Reward Design (score: 0.0154) ✅ DeepSeek-R1

 DeepSeek-R1 논문 (2501.12948v2): Top-5 중 3개 차지

 확인된 사항

 - ✅ papers 테이블에 존재 (citations: 5,471)
 - ✅ chunks 테이블에 존재 (다수 chunk)
 - ✅ embedding_dense: 존재
 - ✅ embedding_sparse: 존재
 - ✅ Hybrid 검색 결과 Top-5 포함

 잠재적 이슈

 1. Latency: 15,323ms (목표의 20배 이상)
 2. token_count: NULL - chunker 파싱 이슈 가능성
 3. UI/프론트엔드 연동: 검색 결과가 UI에 제대로 표시되는지 확인 필요

 권장 사항

 Qdrant 마이그레이션 후 동일 쿼리 재검증:
 - 목표 latency: < 700ms
 - Top-5 에 DeepSeek-R1 유지 확인