[전체 논문 → ML/DL/LLM 관련 Top-1000 논문 선별 전략 초안]

목표:
2025년 1월 ~ 현재(약 14개월) arXiv 전체 논문에서

ML / DL / LLM 관련 논문만 선별

편향 없이 상위 1000개 논문 추출

RAG 실험용 gold dataset 구축

핵심 원칙:

재현 가능성

설명 가능성

편향 최소화

최신성 반영

연구 트렌드 반영

전체 전략 개요:
3단계 필터링 + 2단계 스코어링 + 1단계 균형 보정

전체 논문
→ (1) 고재현율 필터
→ (2) 고정밀 필터
→ (3) 의미 기반 필터
→ (4) 다중 스코어링
→ (5) 분야 균형 보정
→ Top 1000
------

1. 1차 필터: 고재현율(Recall) 중심 — "놓치지 말자"

목표:
ML/DL/LLM 관련 가능성이 조금이라도 있으면 모두 통과

방법:

(A) arXiv category 기반:
cs.AI, cs.LG, cs.CL, cs.CV, stat.ML, cs.IR, cs.NE, cs.RO(부분)

(B) 키워드 기반 확장:
title + abstract에서
transformer, large language model, LLM, diffusion, foundation model,
pretraining, fine-tuning, instruction tuning, RLHF, alignment,
multimodal, vision-language, retrieval augmented, rag, agent, tool calling

결과:
전체 약 15~20만 → 약 2~3만 논문
------

2. 2차 필터: 고정밀(Precision) 필터 — "진짜만 남기자"

목표:
ML/DL/LLM 관련 논문만 고정밀로 분류

방법:
LLM 기반 분류 + 규칙 혼합

입력:
title + abstract

출력 클래스:
0: 무관
1: ML 일반
2: DL
3: LLM 중심
4: 멀티모달
5: 이론 / 통계 기반

Gemini / GPT / Claude를 활용한 batch classification

결과:
약 3만 → 6~8천 논문
------

3. 의미 기반 필터: Semantic filtering

목표:
겉으로 ML이지만 실제 기여가 없는 논문 제거

방법:
Anchor query 정의:
"state of the art research in large language models, deep learning architectures, training optimization, multimodal models, alignment, reasoning"

논문 abstract 임베딩 후 cosine similarity ≥ threshold (예: 0.55)

결과:
약 6~8천 → 4~5천 논문
------

4. 다중 스코어링: 상위 1000 선별 핵심

단순 인용수 정렬은 최신 논문 및 breakthrough 논문을 심각하게 저평가함.

FinalScore =
0.35 * CitationScore

0.25 * RecencyBoost

0.20 * SemanticImpact

0.10 * VenueWeight

0.10 * CommunitySignal

(1) CitationScore:
Semantic Scholar citation / months_since_publication

(2) RecencyBoost:
exp(-age / τ) 형태로 최근 논문 가중치 부여

(3) SemanticImpact:
논문 임베딩 vs anchor query cosine similarity

(4) VenueWeight:
NeurIPS, ICML, ICLR, ACL, EMNLP, CVPR, ICCV, ECCV, AAAI, KDD 등 top venue 가산점

(5) CommunitySignal:
GitHub stars, Twitter/X 언급량, HuggingFace model 연결 여부 등
------

5. 균형 보정: Stratified sampling

목표:
특정 분야 (예: LLM pretraining) 쏠림 방지

권장 분야 비율:

LLM pretraining: 20%

Reasoning / RL / Alignment: 20%

Multimodal: 15%

Retrieval / RAG: 15%

Architecture: 10%

Optimization / Efficiency: 10%

Evaluation / Benchmark: 10%

LLM 기반 분류 + embedding clustering + keyword heuristic 혼합하여 분야 분류

------

최종 파이프라인 요약

전체 논문 (≈200k)
→ 1차 필터 (≈30k)
→ 2차 LLM 분류 (≈6~8k)
→ semantic filtering (≈4~5k)
→ multi-score ranking
→ stratified sampling
→ Top 1000