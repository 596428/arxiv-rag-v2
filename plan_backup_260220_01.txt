Implement the following plan:

  # arXiv RAG v1 - 3가지 주요 개선 계획

  > **프로젝트 목적**: RAG 구조 실험용 research platform
  > **중점 가치**: 실험 재현성, 구조 확장성
  > **작성일**: 2026-02-20

  ---

  ## 요약: 우선순위 및 의존성

  | 우선순위 | 항목 | 예상 소요 | 의존성 |
  |----------|------|-----------|--------|
  | **P1** | Vector DB 분리 (Qdrant + FastAPI) | 9일 | 없음 |
  | **P2** | 데이터 재수집 (14개월) | 5-7일 | **없음 (P1과 병렬)** |
  | **P3** | Qdrant 쿼리 최적화 + 벤치마크 | 2-3일 | P1 완료 후 |

  **확정 실행 순서**: **(P1 || P2 병렬)** → P3 (Qdrant 쿼리 최적화) → 통합 벤치마크

  ### 확정된 설계 결정
  - **배포 방식**: Cloudflare Tunnel (`acacia-dev-tunnel` 기존 설정 활용, acacia.chat 도메인)
  - **데이터 저장 전략**: Raw data → Supabase 유지 / Vectors만 Qdrant 분리
  - **병렬 실행**: P1(Qdrant)와 P2(데이터 수집) 동시 진행
  - **LLM 분류**: `gemini-3-flash-preview` (2025년 12월 최신 모델)
  - **스코어링**: 4가지 지표 (Citation + Recency + Semantic + Stratified)

  ---

  ## P1. Vector DB 분리 (Qdrant + FastAPI)

  ### 1.1 현재 문제
  - Supabase 500MB 한도 초과 (현재 ~9.5GB)
  - Sparse vector 인덱스 미지원 → O(n×m) 성능 (2,599ms/query)
  - ColBERT 저장 시 7일 소요 예상

  ### 1.2 권장 아키텍처

  ```
  ┌─────────────────┐     HTTPS + CORS      ┌─────────────────┐
  │  GitHub Pages   │ ◄──────────────────── │   FastAPI       │
  │  (Static Site)  │    (Cloudflare Tunnel)│   (WSL Docker)  │
  └─────────────────┘      acacia.chat      └────────┬────────┘
  │
  ┌──────────────────────────────────────────┼──────────┐
  │                                          │          │
  ▼                                          ▼          │
  ┌─────────────────┐                       ┌─────────────────┐ │
  │    Qdrant       │                       │    Supabase     │ │
  │   (Docker)      │                       │  (Raw Data)     │ │
  │  - Dense vectors│                       │  - Papers       │ │
  │  - Sparse       │                       │  - Equations    │ │
  │  - ColBERT      │                       │  - Figures      │ │
  │  (Vectors Only) │                       │  (Metadata)     │ │
  └─────────────────┘                       └─────────────────┘ │
  │                                                     │
  └─────────── acacia-dev-tunnel (기존 설정) ───────────┘
  ```

  **저장 분리 전략**:
  - **Supabase**: papers, equations, figures 테이블 유지 (raw data, metadata)
  - **Qdrant**: chunks의 embedding vectors만 저장 (dense, sparse, colbert)

  ### 1.3 Qdrant 컬렉션 스키마
  ```python
  collection_config = {
  "vectors": {
  "dense_bge": {"size": 1024, "distance": "Cosine"},
  "dense_openai": {"size": 1024, "distance": "Cosine"},
  "colbert": {"size": 1024, "multivector": True}  # Late interaction
  },
  "sparse_vectors": {
  "sparse_bge": {}  # Native sparse (inverted index)
  }
  }
  ```

  ### 1.4 FastAPI 엔드포인트 설계
  ```
  POST /api/v1/search
  - mode: dense | sparse | hybrid | colbert | openai
  - query: string
  - top_k: int (default: 10)
  - rerank: bool (default: false)

  POST /api/v1/chat
  - query: string
  - search_mode: string
  - stream: bool

  GET  /api/v1/papers
  GET  /api/v1/papers/{arxiv_id}
  GET  /api/v1/health
  ```

  ### 1.5 Cloudflare Tunnel 설정
  ```bash
  # 기존 터널 확인 (이미 존재)
  cloudflared tunnel list
  # ID: 53e9afc6-16f9-4848-91da-894fc639ebe8
  # NAME: acacia-dev-tunnel

  # 새 서브도메인 추가 (필요시)
  cloudflared tunnel route dns acacia-dev-tunnel api.acacia.chat
  ```

  ### 1.6 구현 일정 (9일)

  | Phase | 기간 | 작업 |
  |-------|------|------|
  | **POC** | 2일 | Qdrant Docker 설정, 1K 샘플 마이그레이션, 벤치마크 |
  | **FastAPI** | 3일 | 엔드포인트 구현, CORS, Tunnel 라우트 추가 |
  | **Migration** | 2일 | 전체 chunks 마이그레이션, 검증 |
  | **Buffer** | 2일 | 최적화, 모니터링 |

  ### 1.7 예상 성능 개선

  | 작업 | 현재 | 예상 | 개선 |
  |------|------|------|------|
  | Sparse Search | 2,599ms | **<500ms** | **5.2x** |
  | Hybrid Search | 3,578ms | ~700ms | **5.1x** |
  | Dense Search | 440ms | ~200ms | 2.2x |

  ### 1.8 구현 파일
  ```
  신규: src/storage/qdrant_client.py
  신규: src/api/main.py            # FastAPI app
  신규: src/api/routes/search.py
  신규: src/api/routes/chat.py
  신규: src/api/routes/papers.py
  신규: scripts/migrate_to_qdrant.py
  신규: docker-compose.yml         # Qdrant + FastAPI
  수정: docs/js/chatbot.js         # API endpoint 변경
  ```

  ---

  ## P2. 데이터 재수집 (14개월)

  ### 2.1 현재 문제
  - 1개월 데이터만 보유 (2025년 1월)
  - 인용수 기반 선별 → 최신 논문 불리 (12:1 불이익)
  - 다양성 제어 없음 (토픽, 카테고리, 기관)

  ### 2.2 수집 전략: 반복적 NG 키워드 학습 파이프라인

  ```
  ┌─────────────────────────────────────────────────────────┐
  │  0단계: 초기 NG 키워드 설정 (Pre-requisite)              │
  │    → NGwords_gpt.txt 기반 11개 카테고리, ~193개 키워드   │
  │    → data/ng_keywords.json 생성                         │
  ├─────────────────────────────────────────────────────────┤
  │                    월별 반복 (14회)                      │
  ├─────────────────────────────────────────────────────────┤
  │  월간 논문 (≈15k)                                       │
  │    → 1단계: Category + Positive Keyword → ~2k           │
  │    → 2단계: NG Keyword 자동 필터링 → edge cases ~500     │
  │    → 3단계: Gemini 분류 + NG 키워드 추출                 │
  │    → 4단계: 사람 검수 → NG 키워드 업데이트               │
  │    → 다음 달로 이동                                      │
  ├─────────────────────────────────────────────────────────┤
  │  14개월 완료 후                                          │
  │    → 5단계: Semantic Filtering → ~4-5k                  │
  │    → 6단계: 다중 스코어링 → 랭킹                         │
  │    → 7단계: Stratified Sampling → Top 1000              │
  └─────────────────────────────────────────────────────────┘
  ```

  **핵심 전략**: Precision ↓, Recall ↑ 로 시작 → 점진적으로 NG 키워드 정교화

  **NG 키워드 소스**: `NGwords_gpt.txt` (GPT 제안, 11개 카테고리)

  ### 2.3 1단계: 기본 필터링 (Category + Positive Keyword)
  ```python
  # arXiv categories
  CATEGORIES = ["cs.AI", "cs.LG", "cs.CL", "cs.CV", "stat.ML", "cs.IR", "cs.NE"]

  # Keywords (기존 arxiv_client.py 활용)
  KEYWORDS = PRIMARY_KEYWORDS + MODEL_FAMILIES + TECHNIQUE_KEYWORDS
  ```
  **예상**: 월간 15k → 2k

  ### 2.4 0단계: 초기 NG 키워드 설정 (Pre-requisite)

  **소스 파일**: `/home/ajh428/projects/arxiv-rag-v1/NGwords_gpt.txt`

  GPT 제안 기반 **11개 카테고리, ~193개 키워드**로 초기화:

  ```python
  # data/ng_keywords.json - 초기 설정
  {
  "version": "2026-02-20",
  "categories": {
  "biomedical": [
  "bio", "biomedical", "biomedicine", "clinical", "medical", "medicine",
  "healthcare", "hospital", "patient", "diagnosis", "therapy", "treatment",
  "disease", "pathology", "radiology", "ultrasound", "x-ray", "ct scan",
  "mri", "medical imaging", "histopathology", "microscopy", "genomics",
  "genome", "proteomics", "protein", "rna", "dna", "gene expression",
  "drug", "drug discovery", "drug design", "pharmacology", "chemistry",
  "molecule", "molecular", "biochemistry", "protein folding", "protein docking"
  ],
  "chemistry_materials": [
  "material science", "materials science", "metallurgy", "crystal",
  "crystallography", "polymer", "nanomaterial", "nanoparticle",
  "composite material", "battery", "lithium ion", "solid state",
  "semiconductor", "photonic", "quantum chemistry", "quantum physics",
  "particle physics", "condensed matter", "thermodynamics", "fluid mechanics",
  "computational fluid dynamics", "cfd", "finite element", "finite element method",
  "fem", "simulation", "numerical simulation", "physics-based modeling",
  "mechanical engineering", "structural analysis"
  ],
  "earth_science": [
  "climate", "climate change", "meteorology", "weather", "forecasting",
  "atmospheric", "geoscience", "geology", "seismology", "earthquake",
  "hydrology", "oceanography", "remote sensing", "satellite imagery",
  "hyperspectral", "lidar", "geospatial", "gis", "topography", "terrain",
  "agriculture", "crop", "soil", "environmental monitoring", "ecology"
  ],
  "robotics_control": [
  "robotics", "robot control", "motion planning", "path planning", "slam",
  "localization", "mapping", "control system", "pid controller", "kalman filter",
  "signal processing", "time series forecasting", "sensor fusion", "radar",
  "sonar", "audio signal processing", "speech enhancement", "speech separation",
  "beamforming"
  ],
  "finance_social": [
  "finance", "financial", "stock market", "trading", "portfolio",
  "risk management", "cryptocurrency", "blockchain", "economics", "economic",
  "macroeconomic", "microeconomic", "game theory", "social network analysis",
  "sociology", "demography", "survey analysis", "behavioral analysis",
  "opinion mining"
  ],
  "domain_cv": [
  "face recognition", "facial expression", "biometric", "fingerprint",
  "iris recognition", "surveillance", "crowd counting", "traffic monitoring",
  "license plate", "object tracking", "pedestrian detection",
  "industrial inspection", "defect detection", "quality inspection"
  ],
  "education_psychology": [
  "education", "educational", "learning analytics", "student performance",
  "intelligent tutoring", "psychology", "cognitive science", "cognitive modeling",
  "behavior modeling", "emotion recognition", "affective computing"
  ],
  "hardware_systems": [
  "fpga", "asic", "vlsi", "circuit design", "hardware acceleration",
  "embedded system", "microcontroller", "operating system kernel",
  "network protocol", "routing algorithm", "wireless communication",
  "5g", "6g", "antenna design"
  ]
  },
  "flat_keywords": [],  # 카테고리 합산 (자동 생성)
  "changelog": []
  }
  ```

  **초기화 스크립트**:
  ```bash
  # NGwords_gpt.txt → data/ng_keywords.json 변환
  python scripts/init_ng_keywords.py
  ```

  ---

  ### 2.5 2단계: NG Keyword 자동 필터링
  ```python
  # 초기 NG 키워드 로드 (193개)
  def load_ng_keywords() -> list:
  with open("data/ng_keywords.json") as f:
  data = json.load(f)
  return data["flat_keywords"]

  NG_KEYWORDS = load_ng_keywords()

  def filter_by_ng_keywords(papers: list, ng_keywords: list) -> tuple:
  """
  Returns:
  (filtered_out, edge_cases)
  """
  filtered_out = []
  edge_cases = []

  for paper in papers:
  text = f"{paper.title} {paper.abstract}".lower()

  # NG 키워드 매칭
  matched_ng = [kw for kw in ng_keywords if kw.lower() in text]

  if matched_ng:
  filtered_out.append(paper)
  else:
  edge_cases.append(paper)

  return filtered_out, edge_cases
  ```
  **예상**: 2k → edge cases ~500

  ### 2.6 3단계: Gemini 분류 + NG 키워드 추출

  ```python
  # gemini-3-flash-preview 사용 (2025년 12월 최신)
  PROMPT = """
  논문 제목: {title}
  초록: {abstract}

  이 논문이 LLM / DL / ML RAG 실험용 데이터셋에 적합한지 판단하세요.

  판단 기준:
  - LLM, foundation model, pretraining, alignment, reasoning, multimodal, RAG, retrieval, architecture 연구는 적합
  - 특정 도메인 응용 (의료, 생물, 화학, 로봇, 기후, 산업, 신호처리, 물리 시뮬레이션 등)은 부적합

  출력:
  1. 적합 여부: YES / NO
  2. NO인 경우, **도메인 기반 단일 키워드** 3개를 추출하세요.
  - 반드시 **짧고 일반적인 도메인 명사**
  - 복합어, 문장형 금지
  - 예: "Medical", "Biology", "Chemistry", "Robotics", "Climate", "Signal", "Finance"

  응답 형식 (엄격히 준수):
  SUITABLE: YES/NO
  NG_KEYWORDS: keyword1, keyword2, keyword3   (NO인 경우만)
  """

  def classify_and_extract_ng(papers: list) -> tuple:
  """
  Returns:
  (suitable_papers, new_ng_keywords)
  """
  suitable = []
  new_ng_keywords = set()

  for paper in papers:
  response = gemini.generate(PROMPT.format(
  title=paper.title,
  abstract=paper.abstract
  ))

  if "SUITABLE: YES" in response:
  suitable.append(paper)
  else:
  # NG 키워드 추출
  keywords = parse_ng_keywords(response)
  new_ng_keywords.update(keywords)

  return suitable, new_ng_keywords
  ```
  **예상**: edge cases 500 → suitable ~300, 새 NG 키워드 ~50

  ### 2.7 4단계: 사람 검수 (Human-in-the-loop)

  ```bash
  # 월별 검수 체크리스트
  1. 새로 추출된 NG 키워드 검토
  2. 오탐 키워드 제거 (LLM 관련 키워드가 포함된 경우)
  3. 누락된 키워드 수동 추가
  4. NG 키워드 파일 업데이트
  5. 다음 달 수집 진행
  ```

  ```python
  # data/ng_keywords.json (버전 관리)
  {
  "version": "2026-02-01",
  "keywords": [...],
  "changelog": [
  {"date": "2026-02-01", "added": [...], "removed": [...]}
  ]
  }
  ```

  ### 2.8 5단계: Semantic Filtering (14개월 완료 후)
  ```python
  ANCHOR_QUERY = """
  state of the art research in large language models,
  deep learning architectures, training optimization,
  multimodal models, alignment, reasoning
  """

  # BGE-M3 임베딩 후 cosine similarity ≥ 0.55
  ```
  **예상**: ~4-5k 논문 확보

  ### 2.9 6단계: 다중 스코어링 (4가지 지표)

  ```python
  FinalScore = (
  0.40 * CitationScore +      # Semantic Scholar citation / months
  0.30 * RecencyBoost +       # exp(-age / τ)
  0.20 * SemanticImpact +     # cosine similarity with anchor
  0.10 * StratifiedBonus      # 분야 균형 가산점
  )

  # τ = 6 (6개월 반감기)
  ```

  **제외된 지표**:
  - VenueWeight: arXiv preprint에서 venue 정보 제한적
  - CommunitySignal: GitHub/Twitter API 복잡도 높음

  ### 2.10 7단계: Stratified Sampling

  ```python
  TOPIC_DISTRIBUTION = {
  "LLM Pretraining": 200,        # 20%
  "Reasoning/RL/Alignment": 200,  # 20%
  "Multimodal": 150,              # 15%
  "Retrieval/RAG": 150,           # 15%
  "Architecture": 100,            # 10%
  "Optimization/Efficiency": 100, # 10%
  "Evaluation/Benchmark": 100,    # 10%
  }
  ```

  **분류 방법**: LLM 분류 + embedding clustering + keyword heuristic 혼합

  ### 2.11 검증 메트릭
  ```
  ✓ Temporal correlation < 0.2 (시간 편향 제거)
  ✓ Topic entropy > 3.5 bits (다양성)
  ✓ Institution Gini < 0.6 (기관 균형)
  ✓ Category coverage: 모든 카테고리 ≥ 5%
  ```

  ### 2.12 구현 파일
  ```
  신규: data/ng_keywords.json            # NG 키워드 저장소 (버전 관리)
  신규: scripts/init_ng_keywords.py      # NGwords_gpt.txt → JSON 변환
  신규: scripts/collect_extended.py      # 14개월 수집
  신규: scripts/filter_ng_keywords.py    # NG 키워드 자동 필터링
  신규: scripts/classify_papers.py       # LLM 분류 + NG 키워드 추출 (gemini-3-flash-preview)
  신규: scripts/semantic_filter.py       # BGE-M3 anchor similarity
  신규: scripts/compute_scores.py        # 다중 스코어링
  신규: scripts/stratified_sample.py     # 분야별 샘플링
  신규: src/collection/ng_keywords.py    # NG 키워드 관리 모듈
  신규: src/collection/selection.py      # Top-1000 알고리즘
  수정: src/collection/arxiv_client.py   # 날짜 범위 확장
  ```

  ---

  ## P3. Qdrant 쿼리 최적화 + 벤치마크

  > **의존성**: P1 (Qdrant 마이그레이션) 완료 후 진행

  ### 3.1 최적화 대상
  - RRF 가중치 튜닝 (dense/sparse/colbert)
  - retrieval depth 최적화 (top_k)
  - Reranker 통합 (BGE-reranker-v2-m3)

  ### 3.2 RRF 가중치 튜닝
  ```python
  # 현재 벤치마크 기반 권장값
  HybridFullRetriever(
  dense_weight=0.2,   # Dense MRR 낮음 (0.433)
  sparse_weight=0.5,  # Sparse MRR 최고 (0.772)
  colbert_weight=0.3, # Late interaction
  )
  ```

  ### 3.3 Retrieval Depth 최적화
  ```python
  # DeepSeek-R1 누락 문제 해결
  top_k = 50  # 기존 20 → 50 (reranking 전)
  final_k = 10  # reranking 후 반환
  ```

  ### 3.4 Reranker 통합
  ```python
  # BGE-reranker-v2-m3 (이미 구현됨)
  # Top-50 retrieval → Rerank → Top-10
  from src.rag.reranker import BGEReranker

  reranker = BGEReranker()
  results = retriever.search(query, top_k=50)
  reranked = reranker.rerank(query, results, top_k=10)
  ```

  ### 3.5 벤치마크 목표

  | 지표 | 현재 | 목표 |
  |------|------|------|
  | MRR | 0.614 | **≥ 0.75** |
  | Hybrid Latency | 3,578ms | **< 700ms** |
  | Sparse Latency | 2,599ms | **< 500ms** |

  ### 3.6 구현 파일
  ```
  수정: src/rag/retriever.py       # Qdrant retriever 클래스
  수정: src/rag/reranker.py        # Reranker 통합
  수정: scripts/06_evaluate.py     # 벤치마크 스크립트
  신규: scripts/tune_weights.py    # 가중치 그리드 서치
  ```

  ---

  ## 4. 검증 계획

  ### P1 검증
  ```bash
  # Qdrant 헬스체크
  curl http://localhost:6333/health

  # API 헬스체크
  curl https://api.acacia.chat/api/v1/health

  # 성공 기준: Sparse latency < 500ms
  ```

  ### P2 검증
  ```bash
  # 다양성 메트릭 검증
  python scripts/compute_diversity.py

  # 성공 기준:
  # - 1000개 논문 수집 완료
  # - Temporal CV < 0.3
  # - Topic entropy > 3.5
  ```

  ### P3 검증
  ```bash
  # 벤치마크 실행
  python scripts/06_evaluate.py

  # 성공 기준: MRR ≥ 0.75, Latency < 700ms
  ```

  ---

  ## 5. 리스크 및 완화 전략

  | 리스크 | 확률 | 영향 | 완화 |
  |--------|------|------|------|
  | Qdrant 성능 미달 | 낮음 | 높음 | POC에서 조기 검증 |
  | LLM 분류 비용 초과 | 중간 | 낮음 | 배치 처리, 캐싱 |
  | 데이터 수집 API 제한 | 중간 | 중간 | 점진적 수집, rate limiting |
  | Cloudflare Tunnel 불안정 | 낮음 | 중간 | 기존 설정 활용으로 리스크 감소 |

  ---

  ## 결론

  **병렬 실행** (P1 || P2):
  - P1: Qdrant + FastAPI 마이그레이션 (9일)
  - P2: 14개월 데이터 재수집 (5-7일)

  **순차 실행** (P3):
  - P3: Qdrant 쿼리 최적화 + 벤치마크 (2-3일)

  **예상 총 소요**: 약 12일 (병렬 실행 시)

  **최종 목표**:
  - **MRR**: 0.614 → **0.75+** (+22%)
  - **Latency**: 3,578ms → **<700ms** (5x 개선)
  - **데이터 커버리지**: 1개월 → **14개월** (14x)
  - **저장 용량**: 500MB 제한 → **무제한**